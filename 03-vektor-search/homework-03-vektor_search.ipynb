{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Zoomcamp 2024 - Module â„–3 - Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings models `multi-qa-distilbert-cos-v1` from [the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embedding for this user question:\n",
    "\n",
    "```python\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "```\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "\n",
    "* ( ) -0.24\n",
    "* ( ) -0.04\n",
    "* (X) 0.07\n",
    "* ( ) 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078222655\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = \"multi-qa-distilbert-cos-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "embeddings = embedding_model.encode(user_question)\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the documents\n",
    "\n",
    "Now we will create the embeddings for the documents.\n",
    "\n",
    "Load the documents with ids that we prepared in the module:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "```\n",
    "\n",
    "We will use only a subset of the questions - the questions for `\"machine-learning-zoomcamp\"`. After filtering, you should have only 375 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Create the embeddings\n",
    "\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix `X`:\n",
    "\n",
    "* Create a list `embeddings`\n",
    "* Iterate over each document\n",
    "* `qa_text = f'{question} {text}'`\n",
    "* compute the embedding for `qa_text`, append to `embeddings`\n",
    "* At the end, let `X = np.array(embeddings)` (`import numpy as np`)\n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses.\n",
    "\n",
    "Answer: `(948, 768)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for doc in documents:\n",
    "    qa_text = f\"{doc['question']} {doc['text']}\"\n",
    "    embeddings.append(embedding_model.encode(qa_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(embeddings)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "\n",
    "We have the embeddings and the query vector. Now let's compute the cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2.\n",
    "\n",
    "The vectors returned from the embedding model are already normalized (you can check it by computing a dot product of a vector with itself - it should return 1.0). This means that in order to compute the cosine similarity, it's sufficient to multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "* ( ) 65.0\n",
    "* ( ) 6.5\n",
    "* (X) 0.65\n",
    "* ( ) 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506573\n"
     ]
    }
   ],
   "source": [
    "v = embedding_model.encode(user_question)\n",
    "scores = X.dot(v)\n",
    "print(scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "We can now compute the similarity between a query vector and all the embeddings.\n",
    "\n",
    "Let's use this to implement our own vector search\n",
    "\n",
    "```python\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)\n",
    "```\n",
    "\n",
    "If you don't understand how the `search` function work:\n",
    "\n",
    "* Ask ChatGPT or any other LLM of your choice to explain the code\n",
    "* Check our pre-course workshop about implementing a search engine [here](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "\n",
    "(Note: you can replace `argsort` with `argpartition` to make it a lot faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will use the hit-rate metric for evaluation.\n",
    "\n",
    "First, load the ground truth dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "Now use the code from the module to calculate the hit-rate of `VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "What did you get?\n",
    "\n",
    "* (X) 0.93\n",
    "* ( ) 0.73\n",
    "* ( ) 0.53\n",
    "* ( ) 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_engine):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        v = embedding_model.encode(q['question'])\n",
    "        results = search_engine.search(v, num_results=5)\n",
    "        relevance = [d['document'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd1f880fc5b4aaaa3e5725eee6e3e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth_embeddings = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    ground_truth_embeddings.append(embedding_model.encode(q['question']))\n",
    "\n",
    "ground_truth_embeddings = np.array(ground_truth_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = VectorSearchEngine(documents=ground_truth, embeddings=ground_truth_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f34c442a694d40b33d5d1258493436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_result = evaluate(ground_truth, search_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.9972677595628415}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch\n",
    "\n",
    "Now let's index these documents with elasticsearch\n",
    "\n",
    "* Create the index with the same settings as in the module (but change the dimensions)\n",
    "* Index the embeddings (note: you've already computed them)\n",
    "\n",
    "After indexing, let's performm the search of the same query from Q1.\n",
    "\n",
    "What's the ID of the document with the highest score?\n",
    "\n",
    "Answer: `OeLsrZABtfWUogOrK7j4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"},\n",
    "            \"id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(ground_truth):\n",
    "    doc[\"text_vector\"] = ground_truth_embeddings[idx]\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "vector_search_user_question = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"field\": \"text_vector\",\n",
    "        \"query_vector\": vector_search_user_question,\n",
    "        \"k\": X.shape[0],\n",
    "        \"num_candidates\": 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es_client.search(index=index_name, knn=query, source=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': 'OeLsrZABtfWUogOrK7j4',\n",
       "  '_score': 0.85088146,\n",
       "  '_source': {'question': 'If I join the course late, can I still participate?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'OuLsrZABtfWUogOrLLgN',\n",
       "  '_score': 0.8340343,\n",
       "  '_source': {'question': 'Will I be able to obtain a certificate if I join the course after it has started?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': '8-LsrZABtfWUogOrJbcJ',\n",
       "  '_score': 0.81525576,\n",
       "  '_source': {'question': 'Where can I sign up for the course?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'P-LsrZABtfWUogOrLLiA',\n",
       "  '_score': 0.8058321,\n",
       "  '_source': {'question': 'Can I start the course anytime?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'SOLsrZABtfWUogOrLbhR',\n",
       "  '_score': 0.7835678,\n",
       "  '_source': {'question': 'What is the initial step after joining the course?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'WuLsrZABtfWUogOrLrjh',\n",
       "  '_score': 0.7782825,\n",
       "  '_source': {'question': \"Should I watch the videos if I didn't take the course in 2021?\"}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'FOLsrZABtfWUogOrKLh4',\n",
       "  '_score': 0.7757224,\n",
       "  '_source': {'question': 'Is it possible to extend the course duration?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'qeLsrZABtfWUogOrZLrC',\n",
       "  '_score': 0.766625,\n",
       "  '_source': {'question': 'Can I proceed with the course without fully understanding the ROC curve?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'E-LsrZABtfWUogOrKLhj',\n",
       "  '_score': 0.7663717,\n",
       "  '_source': {'question': 'Can the course take more than 4 months?'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'SeLsrZABtfWUogOrLbhn',\n",
       "  '_score': 0.75670564,\n",
       "  '_source': {'question': 'How can I view the content of the course?'}}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OeLsrZABtfWUogOrK7j4'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"hits\"][\"hits\"][0][\"_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch\n",
    "\n",
    "The search engine we used in Q4 computed the similarity between the query and ALL the vectors in our database. Usually this not practical, as we may have a lot of data.\n",
    "\n",
    "Elasticsearch uses approximate techniques to make it faster.\n",
    "\n",
    "Let's evaluate how worse the results are when we switch from exact search (as in Q4) to approximate search with Elastic.\n",
    "\n",
    "What's hit-rate for our dataset for Elastic?\n",
    "\n",
    "* (X) 0.93\n",
    "* ( ) 0.73\n",
    "* ( ) 0.53\n",
    "* ( ) 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(vector):\n",
    "    knn = {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"question\", \"course\", \"document\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451cd09b18854c4d897b235038a343aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9972677595628415}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vector_combined_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = embedding_model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(v_q)\n",
    "\n",
    "def evaluate(ground_truth):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = vector_combined_knn(q)\n",
    "        relevance = [d['document'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "    }\n",
    "\n",
    "evaluate(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
